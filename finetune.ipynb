{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"ab21d24a","cell_type":"code","source":"from transformers import SiglipForImageClassification, AutoImageProcessor\nimport os\nimport pandas as pd\nfrom PIL import Image\nfrom datasets import Dataset\nfrom transformers import Trainer, TrainingArguments\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support\nimport torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:40.880539Z","iopub.execute_input":"2025-05-16T21:12:40.880849Z","iopub.status.idle":"2025-05-16T21:12:40.886884Z","shell.execute_reply.started":"2025-05-16T21:12:40.880829Z","shell.execute_reply":"2025-05-16T21:12:40.885752Z"}},"outputs":[],"execution_count":12},{"id":"b3440522","cell_type":"code","source":"! apt-get install -y gdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:48.095625Z","iopub.execute_input":"2025-05-16T21:12:48.095997Z","iopub.status.idle":"2025-05-16T21:12:50.961812Z","shell.execute_reply.started":"2025-05-16T21:12:48.095963Z","shell.execute_reply":"2025-05-16T21:12:50.960434Z"}},"outputs":[{"name":"stdout","text":"Reading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nE: Unable to locate package gdown\n","output_type":"stream"}],"execution_count":13},{"id":"476daad5-a99d-4678-a522-c51345749867","cell_type":"code","source":"# download zip from google drive and unzip contents\n! gdown --id 1rbISVuHbT_AJPw4wv4ywLym3TLVuGLDH      ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:53.038761Z","iopub.execute_input":"2025-05-16T21:12:53.039286Z","iopub.status.idle":"2025-05-16T21:13:32.279365Z","shell.execute_reply.started":"2025-05-16T21:12:53.039236Z","shell.execute_reply":"2025-05-16T21:13:32.277763Z"}},"outputs":[{"name":"stdout","text":"/usr/local/lib/python3.11/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n  warnings.warn(\nDownloading...\nFrom (original): https://drive.google.com/uc?id=1rbISVuHbT_AJPw4wv4ywLym3TLVuGLDH\nFrom (redirected): https://drive.google.com/uc?id=1rbISVuHbT_AJPw4wv4ywLym3TLVuGLDH&confirm=t&uuid=cc14b690-55c4-4f67-883d-d84889fdd616\nTo: /kaggle/working/frames_and_annotations.zip\n100%|██████████████████████████████████████| 1.14G/1.14G [00:28<00:00, 39.8MB/s]\n","output_type":"stream"}],"execution_count":14},{"id":"76737129-e66d-45ee-84ca-65586cd6438d","cell_type":"code","source":"# Unzip the file\nimport zipfile\nwith zipfile.ZipFile(\"./frames_and_annotations.zip\", \"r\") as zip_ref:\n    zip_ref.extractall(\"frames\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:13:32.281448Z","iopub.execute_input":"2025-05-16T21:13:32.281937Z","iopub.status.idle":"2025-05-16T21:13:42.077352Z","shell.execute_reply.started":"2025-05-16T21:13:32.281901Z","shell.execute_reply":"2025-05-16T21:13:42.075895Z"}},"outputs":[],"execution_count":15},{"id":"d96a7c86-9c6e-4e49-a717-c9d828f39fba","cell_type":"code","source":"df = pd.read_csv(\"./frames/frames_annotations.csv\")\n\n# fix backslash to forward slash in relative paths\ndf[\"image\"] = df[\"image\"].apply(lambda x: os.path.join(\"frames\", x.replace(\"\\\\\", \"/\")))\n\n#assign labels\ndf[\"label\"] = df[\"label\"].map({\"not_taking_medication\": 0, \"taking_medication\": 1})\n\n# generate dataset from df\ndataset = Dataset.from_pandas(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:13:46.401358Z","iopub.execute_input":"2025-05-16T21:13:46.401699Z","iopub.status.idle":"2025-05-16T21:13:46.473620Z","shell.execute_reply.started":"2025-05-16T21:13:46.401674Z","shell.execute_reply":"2025-05-16T21:13:46.472377Z"}},"outputs":[],"execution_count":16},{"id":"1b77880b","cell_type":"code","source":"model = SiglipForImageClassification.from_pretrained(\"prithivMLmods/Human-Action-Recognition\")\nprocessor = AutoImageProcessor.from_pretrained(\"prithivMLmods/Human-Action-Recognition\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:13:51.723917Z","iopub.execute_input":"2025-05-16T21:13:51.724274Z","iopub.status.idle":"2025-05-16T21:13:52.518701Z","shell.execute_reply.started":"2025-05-16T21:13:51.724250Z","shell.execute_reply":"2025-05-16T21:13:52.517576Z"}},"outputs":[],"execution_count":17},{"id":"6a0ad2c1","cell_type":"code","source":"def preprocess(example):\n    image = Image.open(example[\"image\"]).convert(\"RGB\")\n    inputs = processor(images=image, return_tensors=\"pt\")\n    inputs[\"labels\"] = example[\"label\"]\n    return {\n        \"pixel_values\": inputs[\"pixel_values\"].squeeze(),\n        \"labels\": inputs[\"labels\"]\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:13:53.937619Z","iopub.execute_input":"2025-05-16T21:13:53.937972Z","iopub.status.idle":"2025-05-16T21:13:53.944640Z","shell.execute_reply.started":"2025-05-16T21:13:53.937948Z","shell.execute_reply":"2025-05-16T21:13:53.943164Z"}},"outputs":[],"execution_count":18},{"id":"97101522","cell_type":"code","source":"dataset = dataset.map(preprocess, remove_columns=[\"image\", \"label\"])\ndataset = dataset.train_test_split(test_size=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:13:55.915501Z","iopub.execute_input":"2025-05-16T21:13:55.915864Z","iopub.status.idle":"2025-05-16T21:14:51.037561Z","shell.execute_reply.started":"2025-05-16T21:13:55.915833Z","shell.execute_reply":"2025-05-16T21:14:51.036335Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/850 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7a91017111524fd3ab1002d305468f5f"}},"metadata":{}}],"execution_count":19},{"id":"02a5111d","cell_type":"code","source":"def compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    # Ensure logits are numpy arrays\n    if isinstance(logits, tuple):\n        print(\"logits is tuple\")\n        logits = logits[0]\n    if isinstance(logits, torch.Tensor):\n        print(\"logits is tensor\")\n        logits = logits.detach().cpu().numpy()\n    if isinstance(labels, torch.Tensor):\n        print(\"labels is tensor\")\n        labels = labels.detach().cpu().numpy()\n    preds = np.argmax(logits, axis=1)\n    acc = accuracy_score(labels, preds)\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"binary\", zero_division=0)\n    return {\n        \"accuracy\": acc,\n        \"precision\": precision,\n        \"recall\": recall,\n        \"f1\": f1,\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:26.186763Z","iopub.execute_input":"2025-05-16T21:12:26.187244Z","iopub.status.idle":"2025-05-16T21:12:26.194817Z","shell.execute_reply.started":"2025-05-16T21:12:26.187200Z","shell.execute_reply":"2025-05-16T21:12:26.193725Z"}},"outputs":[],"execution_count":10},{"id":"2030c48a","cell_type":"code","source":"model.config.label2id = {\"not_taking_medication\": 0, \"taking_medication\": 1}\nmodel.config.id2label = {0: \"not_taking_medication\", 1: \"taking_medication\"}\n\ntraining_args = TrainingArguments(\n    output_dir=\"./HAR-medication-finetuned\",\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    num_train_epochs=3,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    hub_model_id=\"Adekiii/HAR-medication-finetuned\",\n    report_to=[\"none\"],\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset[\"train\"],\n    eval_dataset=dataset[\"test\"],\n    compute_metrics=compute_metrics,\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a5a779f6-8731-4422-bb63-3c71d239a34f","cell_type":"code","source":"# Use GPU if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"263c6e9d","cell_type":"code","source":"trainer.train()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"0aa83ffa","cell_type":"code","source":"trainer.save_model(\"./HAR-med-finetunedv2\")\nprocessor.save_pretrained(\"./HAR-med-finetunedv2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:27.273561Z","iopub.status.idle":"2025-05-16T21:12:27.274018Z","shell.execute_reply.started":"2025-05-16T21:12:27.273800Z","shell.execute_reply":"2025-05-16T21:12:27.273823Z"}},"outputs":[],"execution_count":null},{"id":"c01f732a","cell_type":"code","source":"from huggingface_hub import HfApi\n\naccess_token = \"...\"\n\napi = HfApi(token=access_token)\napi.upload_folder(\n    folder_path=\"HAR-med-finetunedv2\",\n    repo_id=\"tam6/HAR-medication-finetunedv2\", # change with own repo\n    repo_type=\"model\",\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"a552eca1-ed3e-4078-9784-9a24c3b7a09c","cell_type":"code","source":"# Load the processor and model from the HuggingFace Hub\nprocessor = AutoImageProcessor.from_pretrained(\"Adekiii/HAR-medication-finetuned\")\nmodel = SiglipForImageClassification.from_pretrained(\"Adekiii/HAR-medication-finetuned\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:14:59.062124Z","iopub.execute_input":"2025-05-16T21:14:59.062502Z","iopub.status.idle":"2025-05-16T21:14:59.839393Z","shell.execute_reply.started":"2025-05-16T21:14:59.062479Z","shell.execute_reply":"2025-05-16T21:14:59.837191Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_95/2745468205.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the processor and model from the HuggingFace Hub\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoImageProcessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adekiii/HAR-medication-finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSiglipForImageClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Adekiii/HAR-medication-finetuned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0mold_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_default_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, weights_only, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   4397\u001b[0m                 \u001b[0moffload_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4398\u001b[0m                 \u001b[0merror_msgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4399\u001b[0;31m             \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_pretrained_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4400\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4401\u001b[0m                 \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_pretrained_model\u001b[0;34m(cls, model, state_dict, checkpoint_files, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, device_map, disk_offload_folder, offload_state_dict, dtype, hf_quantizer, keep_in_fp32_regex, device_mesh, key_mapping, weights_only)\u001b[0m\n\u001b[1;32m   4831\u001b[0m             \u001b[0;31m# Skip it with fsdp on ranks other than 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4832\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_fsdp_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_quantized\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4833\u001b[0;31m                 disk_offload_index, cpu_offload_index = _load_state_dict_into_meta_model(\n\u001b[0m\u001b[1;32m   4834\u001b[0m                     \u001b[0mmodel_to_load\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4835\u001b[0m                     \u001b[0mstate_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_state_dict_into_meta_model\u001b[0;34m(model, state_dict, shard_file, expected_keys, reverse_renaming_mapping, device_map, disk_offload_folder, disk_offload_index, cpu_offload_folder, cpu_offload_index, hf_quantizer, is_safetensors, keep_in_fp32_regex, unexpected_keys, device_mesh)\u001b[0m\n\u001b[1;32m    822\u001b[0m                     \u001b[0mparam_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mis_local_dist_rank_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"meta\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 824\u001b[0;31m                 \u001b[0m_load_parameter_into_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36m_load_parameter_into_model\u001b[0;34m(model, param_name, tensor)\u001b[0m\n\u001b[1;32m    710\u001b[0m     \u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_module_from_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m     \u001b[0;31m# This will check potential shape mismatch if skipped before\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m     \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mparam_type\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0massign\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    713\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2581\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2582\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2583\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Linear:\n\tsize mismatch for bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([2])."],"ename":"RuntimeError","evalue":"Error(s) in loading state_dict for Linear:\n\tsize mismatch for bias: copying a param with shape torch.Size([15]) from checkpoint, the shape in current model is torch.Size([2]).","output_type":"error"}],"execution_count":20},{"id":"3dae158d-d3f4-4d3f-a511-f46166ccadf7","cell_type":"code","source":"test_data = dataset[\"test\"]\nprint(test_data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:15:40.111751Z","iopub.execute_input":"2025-05-16T21:15:40.112136Z","iopub.status.idle":"2025-05-16T21:15:40.117511Z","shell.execute_reply.started":"2025-05-16T21:15:40.112102Z","shell.execute_reply":"2025-05-16T21:15:40.116467Z"}},"outputs":[{"name":"stdout","text":"Dataset({\n    features: ['pixel_values', 'labels'],\n    num_rows: 85\n})\n","output_type":"stream"}],"execution_count":22},{"id":"879a268e-657d-4116-837b-35d6b76c44ab","cell_type":"code","source":"print(dataset)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"id":"074d14d6-856e-425b-85a3-da92e992e7bb","cell_type":"code","source":"#inputs = processor(images=test_data[\"pixel_values\"], return_tensors=\"pt\")\nprint('succeed')\n# Run inference\npredicted_labels = []\ntrue_labels = test_data[\"label\"]\ninputs = test_data[\"pixel_values\"]\nprint(inputs.type)\n\nfor frame in inputs:\n    output = model(frame)\n    logits = outputs.logits\n    predicted_class_idx = logits.argmax(-1).item()\n    predicted_labels.append(predicted_class_idx)\n\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_labels, average=\"binary\", zero_division=0)\n\n\"\"\"\nwith torch.no_grad():\n    #for im in test_data[\"pixel_values\"]\n    outputs = model(**inputs)\n    logits = outputs.logits\n    predicted_class_idx = logits.argmax(-1).item()\n    #predicted_labels.append(predicted_class_idx)\nprecision, recall, f1, _ = precision_recall_fscore_support(true_labels, predicted_class_idx, average=\"binary\", zero_division=0)\n\"\"\"","metadata":{"trusted":true,"execution":{"execution_failed":"2025-05-16T21:18:58.013Z"}},"outputs":[],"execution_count":null},{"id":"afd3b86a-052c-46f8-b3f9-d57bd0f96786","cell_type":"code","source":"print(\"f1 score on test set: \" + str(f1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-16T21:12:27.282336Z","iopub.status.idle":"2025-05-16T21:12:27.282730Z","shell.execute_reply.started":"2025-05-16T21:12:27.282557Z","shell.execute_reply":"2025-05-16T21:12:27.282576Z"}},"outputs":[],"execution_count":null},{"id":"f91284d9-ebb9-4675-ab0a-a5d775a58119","cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}