{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:30:06.880141Z",
     "iopub.status.busy": "2025-04-24T07:30:06.879766Z",
     "iopub.status.idle": "2025-04-24T07:30:15.179766Z",
     "shell.execute_reply": "2025-04-24T07:30:15.178204Z",
     "shell.execute_reply.started": "2025-04-24T07:30:06.880116Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mediapy in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (1.2.4)\n",
      "Requirement already satisfied: ipython in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from mediapy) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from mediapy) (3.10.1)\n",
      "Requirement already satisfied: numpy in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from mediapy) (2.2.5)\n",
      "Requirement already satisfied: Pillow in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from mediapy) (11.2.1)\n",
      "Requirement already satisfied: decorator in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (0.6.3)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from ipython->mediapy) (5.14.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (25.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from matplotlib->mediapy) (2.9.0.post0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from jedi>=0.16->ipython->mediapy) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from pexpect>4.3->ipython->mediapy) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython->mediapy) (0.2.13)\n",
      "Requirement already satisfied: six>=1.5 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from python-dateutil>=2.7->matplotlib->mediapy) (1.17.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from stack_data->ipython->mediapy) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from stack_data->ipython->mediapy) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from stack_data->ipython->mediapy) (0.2.3)\n",
      "Requirement already satisfied: gdown in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (5.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from gdown) (3.17.0)\n",
      "Requirement already satisfied: requests[socks] in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from gdown) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from gdown) (4.67.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests[socks]->gdown) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests[socks]->gdown) (2025.4.26)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Requirement already satisfied: transformers in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (4.51.3)\n",
      "Requirement already satisfied: filelock in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install mediapy\n",
    "!pip install -U gdown\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:30:15.182224Z",
     "iopub.status.busy": "2025-04-24T07:30:15.181833Z",
     "iopub.status.idle": "2025-04-24T07:30:15.231043Z",
     "shell.execute_reply": "2025-04-24T07:30:15.230090Z",
     "shell.execute_reply.started": "2025-04-24T07:30:15.182190Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bobby/miniconda3/envs/i_work/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Callable\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import albumentations as A\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import mediapy as media\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from datasets import Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    SiglipForImageClassification,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get raw videos from google drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:26:31.779214Z",
     "iopub.status.busy": "2025-04-24T07:26:31.778997Z",
     "iopub.status.idle": "2025-04-24T07:26:46.577421Z",
     "shell.execute_reply": "2025-04-24T07:26:46.576198Z",
     "shell.execute_reply.started": "2025-04-24T07:26:31.779196Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!gdown https://drive.google.com/drive/folders/1Y8W5yiAxTDiRzx_9-caqa9dNhmo4dYcS --folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:26:46.580592Z",
     "iopub.status.busy": "2025-04-24T07:26:46.580300Z",
     "iopub.status.idle": "2025-04-24T07:26:46.587847Z",
     "shell.execute_reply": "2025-04-24T07:26:46.586482Z",
     "shell.execute_reply.started": "2025-04-24T07:26:46.580566Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "PATH_CWD = os.getcwd()\n",
    "PATH_DATA = os.path.join(PATH_CWD + \"/AI in PWF/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/bobby/repos/medication-intake-detection-master-challenge/AI in PWF/data/'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH_DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:26:46.589565Z",
     "iopub.status.busy": "2025-04-24T07:26:46.589206Z",
     "iopub.status.idle": "2025-04-24T07:26:54.290596Z",
     "shell.execute_reply": "2025-04-24T07:26:54.289653Z",
     "shell.execute_reply.started": "2025-04-24T07:26:46.589535Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "video_zip_file = (\n",
    "    PATH_DATA + \"raw videos/Dataset_AI_Masterchallange 2025-20250424T063117Z-001.zip\"\n",
    ")\n",
    "with ZipFile(video_zip_file, \"r\") as video_zip:\n",
    "    video_zip.extractall(path=PATH_DATA + \"raw videos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:26:54.292272Z",
     "iopub.status.busy": "2025-04-24T07:26:54.291925Z",
     "iopub.status.idle": "2025-04-24T07:26:54.810784Z",
     "shell.execute_reply": "2025-04-24T07:26:54.809533Z",
     "shell.execute_reply.started": "2025-04-24T07:26:54.292229Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "os.remove(video_zip_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:31:24.062878Z",
     "iopub.status.busy": "2025-04-24T07:31:24.062526Z",
     "iopub.status.idle": "2025-04-24T07:31:24.069211Z",
     "shell.execute_reply": "2025-04-24T07:31:24.067734Z",
     "shell.execute_reply.started": "2025-04-24T07:31:24.062855Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def play_video(fname):\n",
    "    fname = PATH_DATA + fname\n",
    "    video = media.read_video(fname)\n",
    "    media.show_video(video, title=fname.split(\"/\")[-1].split(\".\")[0], fps=60, width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T07:31:26.350413Z",
     "iopub.status.busy": "2025-04-24T07:31:26.350125Z",
     "iopub.status.idle": "2025-04-24T07:32:26.820223Z",
     "shell.execute_reply": "2025-04-24T07:32:26.818836Z",
     "shell.execute_reply.started": "2025-04-24T07:31:26.350394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "play_video(\"raw videos/Dataset_AI_Masterchallange 2025/video_20250328_011625.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_dir,\n",
    "        frames_per_video: int = 60,\n",
    "        transform: Callable = None,\n",
    "        type_: str = \"train\",\n",
    "        split_: float = 0.8,\n",
    "        frame_based: bool = True,\n",
    "    ):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.type_ = type_\n",
    "        self.split_ = split_\n",
    "        self.frame_based = (\n",
    "            frame_based  # determmines if dataset returns frames or videos\n",
    "        )\n",
    "        self.video_files, self.video_labels = self._load_video_files(data_dir)\n",
    "        self.frames_per_video = frames_per_video\n",
    "        self.set_mean = None\n",
    "        self.set_std = None\n",
    "        self.data = [\n",
    "            {\"video_path\": fname, \"label\": self.video_labels[fname][0]}\n",
    "            for fname in self.video_files\n",
    "        ]\n",
    "\n",
    "    def _load_video_files(self, data_dir):\n",
    "        self.video_dir = os.path.join(\n",
    "            data_dir, \"raw videos/Dataset_AI_Masterchallange 2025\"\n",
    "        )\n",
    "\n",
    "        video_files = [\n",
    "            name.split(\"/\")[-1]\n",
    "            for name in os.listdir(self.video_dir)\n",
    "            if name.endswith(\".mp4\")\n",
    "        ]\n",
    "\n",
    "        labels_df = pd.read_csv(os.path.join(data_dir, \"annotations_mid.csv\"))\n",
    "\n",
    "        labels = defaultdict(tuple)\n",
    "        for _, row in labels_df.iterrows():\n",
    "            labels[row[\"filename\"]] = (row[\"label\"], row[\"edge_case\"])\n",
    "\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(video_files)\n",
    "        split_idx = int(len(video_files) * self.split_)\n",
    "        if self.type_ == \"train\":\n",
    "            self.video_files = video_files[:split_idx]\n",
    "        else:  # validation or test\n",
    "            self.video_files = video_files[split_idx:]\n",
    "        labels = {k: labels[k] for k in video_files}\n",
    "\n",
    "        return video_files, labels\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert (\n",
    "            self.set_mean is not None and self.set_std is not None\n",
    "        ), \"Call get_statistics() first\"\n",
    "\n",
    "        if self.frame_based:\n",
    "            # Frame-based training (individual frames)\n",
    "            video_idx = index // self.frames_per_video\n",
    "            frame_idx = index % self.frames_per_video\n",
    "            frames, label, _ = self.__load(video_idx)\n",
    "            frame = frames[frame_idx]\n",
    "            # frame = (frame - self.set_mean) / self.set_std\n",
    "            if self.transform:\n",
    "                frame = self.transform(images=frame, return_tensors=\"pt\")[\n",
    "                    \"pixel_values\"\n",
    "                ].squeeze(0)\n",
    "            return {\n",
    "                \"pixel_values\": frame,  # Single frame\n",
    "                \"label\": torch.tensor(\n",
    "                    label, dtype=torch.long\n",
    "                ),  # Convert label to tensor\n",
    "            }\n",
    "        else:\n",
    "            # Video-based evaluation (all frames)\n",
    "            frames, label, _ = self.__load(index)\n",
    "            frames = (frames - self.set_mean) / self.set_std\n",
    "            processed_frames = (\n",
    "                [\n",
    "                    self.transform(images=frame, return_tensors=\"pt\")[\n",
    "                        \"pixel_values\"\n",
    "                    ].squeeze(0)\n",
    "                    for frame in frames\n",
    "                ]\n",
    "                if self.transform\n",
    "                else frames\n",
    "            )\n",
    "            return {\n",
    "                \"pixel_values\": torch.stack(processed_frames),  # All frames stacked\n",
    "                \"label\": torch.tensor(label, dtype=torch.long),\n",
    "            }\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.frame_based:\n",
    "            return len(self.video_files) * self.frames_per_video\n",
    "        else:\n",
    "            return len(self.video_files)\n",
    "\n",
    "    def __load(self, index):\n",
    "        video_path = os.path.join(self.video_dir, self.video_files[index])\n",
    "        label, edge_case = self.video_labels[self.video_files[index]]\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Warning: Could not open video {video_path}\")\n",
    "            return np.zeros(\n",
    "                (self.frames_per_video, 224, 224, 3), label, edge_case\n",
    "            )  # Return dummy data\n",
    "\n",
    "        ret = True\n",
    "        frames = []\n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        sample_interval = max(frame_count // self.frames_per_video, 1)\n",
    "        pbar = tqdm(total=frame_count)\n",
    "        current_idx = 0\n",
    "        last_valid_frame = None\n",
    "\n",
    "        while len(frames) < self.frames_per_video:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                # Reached end of video early - pad with last valid frame\n",
    "                if last_valid_frame is not None:\n",
    "                    frames.extend(\n",
    "                        [last_valid_frame] * (self.frames_per_video - len(frames))\n",
    "                    )\n",
    "                break\n",
    "            if current_idx % sample_interval == 0:\n",
    "                frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "                # Basic corruption check\n",
    "                if np.mean(frame) < 1e-6:  # Mostly black frame\n",
    "                    if last_valid_frame is not None:\n",
    "                        frame = last_valid_frame\n",
    "                    else:\n",
    "                        continue\n",
    "                frames.append(frame)\n",
    "                last_valid_frame = frame\n",
    "            current_idx += 1\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "        # In case we collected less than required, pad with zeros using the first frame shape\n",
    "        if len(frames) < self.frames_per_video:\n",
    "            pad_frame = (\n",
    "                np.zeros_like(frames[0])\n",
    "                if frames\n",
    "                else np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "            )\n",
    "            frames += [pad_frame] * (self.frames_per_video - len(frames))\n",
    "\n",
    "        # Convert to numpy array\n",
    "        frames = np.array(frames)\n",
    "        cap.release()\n",
    "        return frames, label, edge_case\n",
    "\n",
    "    def get_statistics(self):\n",
    "        data_size = len(self.video_files)\n",
    "        total_sum = np.zeros(3)\n",
    "        total_sq_sum = np.zeros(3)\n",
    "        total_count = np.zeros(3)\n",
    "        for i in range(data_size):\n",
    "            frames, _, _ = self.__load(i)\n",
    "            frames_np = np.array(frames)  # shape: (num_frames, H, W, C)\n",
    "            # Reshape to (-1, 3) to flatten all pixels, then sum per channel\n",
    "            pixels = frames_np.reshape(-1, frames_np.shape[-1])\n",
    "            total_sum += pixels.sum(axis=0)\n",
    "            total_sq_sum += (pixels**2).sum(axis=0)\n",
    "            total_count += pixels.shape[0]\n",
    "\n",
    "        self.set_mean = total_sum / total_count\n",
    "        self.set_std = np.sqrt((total_sq_sum / total_count) - (self.set_mean**2) + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"prithivMLmods/Human-Action-Recognition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/761 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 709/761 [00:02<00:00, 298.66it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 304.77it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 305.59it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 310.49it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 303.79it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 306.39it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 309.31it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 314.18it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 308.49it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 315.05it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 312.06it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 306.09it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 303.48it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 291.27it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 302.92it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 311.35it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 303.41it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 303.01it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 295.28it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 298.76it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 306.25it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 303.38it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 305.21it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 310.69it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 299.99it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 304.80it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 302.61it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 291.93it/s]\n",
      " 93%|█████████▎| 709/759 [00:02<00:00, 296.55it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 301.12it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 304.91it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 299.05it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 305.20it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 303.95it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 305.09it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 304.57it/s]\n",
      " 92%|█████████▏| 709/774 [00:02<00:00, 306.36it/s]\n",
      " 98%|█████████▊| 768/780 [00:02<00:00, 308.94it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 298.60it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 306.53it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 302.88it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 303.39it/s]\n",
      " 91%|█████████ | 709/778 [00:02<00:00, 299.90it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 300.54it/s]\n",
      " 94%|█████████▍| 709/756 [00:02<00:00, 301.27it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 301.47it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 296.01it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 307.11it/s]\n",
      " 89%|████████▉ | 296/333 [00:01<00:00, 255.92it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 307.15it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 308.99it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 305.84it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 294.47it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 295.78it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 296.34it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 303.76it/s]\n",
      " 98%|█████████▊| 768/786 [00:02<00:00, 303.71it/s]\n",
      " 97%|█████████▋| 473/489 [00:01<00:00, 279.39it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 293.19it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 306.39it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 300.29it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 302.18it/s]\n",
      " 98%|█████████▊| 768/786 [00:02<00:00, 303.91it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 298.35it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 297.88it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 294.02it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 303.61it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 301.31it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 298.23it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 296.69it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 299.25it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 295.57it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 301.08it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 302.51it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 292.75it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 300.55it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 310.39it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 311.02it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 304.24it/s]\n",
      " 96%|█████████▋| 752/780 [00:02<00:00, 318.46it/s][h264 @ 0x14bb0000] error while decoding MB 74 67, bytestream -8\n",
      " 98%|█████████▊| 768/780 [00:02<00:00, 307.03it/s]\n",
      " 94%|█████████▎| 709/757 [00:02<00:00, 298.31it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 307.31it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 298.96it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 307.23it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 304.65it/s]\n",
      "/tmp/ipykernel_25677/1026024321.py:174: RuntimeWarning: invalid value encountered in sqrt\n",
      "  self.set_std = np.sqrt((total_sq_sum / total_count) - (self.set_mean**2) + 1e-8)\n"
     ]
    }
   ],
   "source": [
    "training_set = VideoDataset(\n",
    "    data_dir=PATH_DATA, transform=processor, type_=\"train\", split_=0.8, frame_based=True\n",
    ")\n",
    "training_set.get_statistics()  # running separately because we should only take training set statistics for normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_frame = VideoDataset(\n",
    "    data_dir=PATH_DATA,\n",
    "    transform=processor,\n",
    "    type_=\"validation\",\n",
    "    split_=0.8,\n",
    "    frame_based=True,\n",
    ")\n",
    "val_set_frame.set_mean = training_set.set_mean\n",
    "val_set_frame.set_std = training_set.set_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set_video = VideoDataset(\n",
    "    data_dir=PATH_DATA,\n",
    "    transform=processor,\n",
    "    type_=\"validation\",\n",
    "    split_=0.8,\n",
    "    frame_based=False,\n",
    ")\n",
    "val_set_video.set_mean = training_set.set_mean\n",
    "val_set_video.set_std = training_set.set_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SiglipForImageClassification.from_pretrained(\n",
    "    \"prithivMLmods/Human-Action-Recognition\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=1)\n",
    "\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "        labels, preds, average=\"binary\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": acc,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.label2id = {\"not_taking_medication\": 0, \"taking_medication\": 1}\n",
    "model.config.id2label = {0: \"not_taking_medication\", 1: \"taking_medication\"}\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./HAR-medication-finetuned\",\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    num_train_epochs=3,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    remove_unused_columns=False,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=training_set,\n",
    "    eval_dataset=val_set_frame,  # Frame-based for validation during training\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/787 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 768/787 [00:02<00:00, 309.92it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 306.08it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 299.20it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 296.24it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 301.52it/s]\n",
      " 91%|█████████ | 709/778 [00:02<00:00, 302.55it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 302.74it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 299.50it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 304.72it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 298.99it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 313.05it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 309.11it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 304.42it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 301.43it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 305.34it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 308.59it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='1914' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  26/1914 07:58 < 10:27:05, 0.05 it/s, Epoch 0.04/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 709/765 [00:02<00:00, 305.65it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 300.75it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 305.47it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 304.88it/s]\n",
      " 91%|█████████ | 709/778 [00:02<00:00, 303.27it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 303.26it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 303.10it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 323.74it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 307.74it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 307.00it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 314.56it/s]\n",
      " 93%|█████████▎| 709/759 [00:02<00:00, 307.68it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 315.24it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 322.66it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 305.57it/s]\n",
      " 94%|█████████▍| 709/756 [00:02<00:00, 302.25it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 309.08it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 301.90it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 298.93it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 297.02it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 293.71it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 303.15it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 300.94it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 322.21it/s]\n",
      " 91%|█████████ | 709/778 [00:02<00:00, 303.60it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 304.34it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 318.46it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 302.18it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 301.17it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 311.62it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 315.32it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 297.46it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 303.32it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 309.58it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 301.97it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 302.02it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 301.01it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 320.13it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 308.41it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 299.51it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 315.17it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 307.13it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 302.24it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 302.80it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 319.35it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 300.60it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 317.32it/s]\n",
      " 93%|█████████▎| 709/759 [00:02<00:00, 302.44it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 303.80it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 317.01it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 298.03it/s]\n",
      " 91%|█████████ | 709/778 [00:02<00:00, 301.72it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 304.79it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 305.40it/s]\n",
      " 98%|█████████▊| 768/780 [00:02<00:00, 318.98it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 300.04it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 305.29it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 305.30it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 299.60it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 298.36it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 303.84it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 297.13it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 301.12it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 297.69it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 300.98it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 302.67it/s]\n",
      " 94%|█████████▎| 709/757 [00:02<00:00, 307.11it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 306.40it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 310.63it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 303.16it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 322.88it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 302.14it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 314.18it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 299.86it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 307.74it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 301.68it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 302.92it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 306.54it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 321.11it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 306.93it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 313.31it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 301.57it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 315.90it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 299.81it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 322.14it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 305.72it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 303.09it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 323.18it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 312.32it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 307.41it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 307.99it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 314.36it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 303.48it/s]\n",
      " 92%|█████████▏| 709/774 [00:02<00:00, 298.66it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 297.13it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 302.92it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 301.97it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 306.86it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 306.58it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 301.47it/s]\n",
      " 97%|█████████▋| 473/489 [00:01<00:00, 279.02it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 304.46it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 323.67it/s]\n",
      " 93%|█████████▎| 709/760 [00:02<00:00, 303.57it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 310.07it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 305.47it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 321.12it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 298.25it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 305.85it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 318.00it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 307.02it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 303.17it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 305.18it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 298.80it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 299.97it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 305.20it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 301.54it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 321.00it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 297.51it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 298.81it/s]\n",
      " 95%|█████████▌| 744/780 [00:02<00:00, 303.44it/s][h264 @ 0x36455d80] error while decoding MB 74 67, bytestream -8\n",
      " 98%|█████████▊| 768/780 [00:02<00:00, 302.55it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 304.71it/s]\n",
      " 94%|█████████▍| 709/756 [00:02<00:00, 304.71it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 325.64it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 302.98it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 310.54it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 301.85it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 304.12it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 312.93it/s]\n",
      " 93%|█████████▎| 709/759 [00:02<00:00, 303.81it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 320.11it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 319.52it/s]\n",
      " 93%|█████████▎| 709/759 [00:02<00:00, 301.12it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 297.81it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 304.42it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 302.63it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 299.50it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 307.09it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 314.80it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 318.71it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 305.11it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 320.01it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 300.15it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 297.04it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 309.51it/s]\n",
      " 93%|█████████▎| 709/762 [00:02<00:00, 301.86it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 307.78it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 306.04it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 298.67it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 304.76it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 305.14it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 303.53it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 309.79it/s]\n",
      " 98%|█████████▊| 768/786 [00:02<00:00, 305.65it/s]\n",
      " 92%|█████████▏| 709/768 [00:02<00:00, 295.77it/s]\n",
      " 92%|█████████▏| 709/767 [00:02<00:00, 296.64it/s]\n",
      " 98%|█████████▊| 768/786 [00:02<00:00, 319.77it/s]\n",
      " 92%|█████████▏| 709/772 [00:02<00:00, 300.83it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 319.64it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 302.56it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 303.05it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 312.56it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 300.85it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 300.07it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 323.54it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 305.27it/s]\n",
      " 93%|█████████▎| 709/766 [00:02<00:00, 305.80it/s]\n",
      " 97%|█████████▋| 473/489 [00:01<00:00, 284.13it/s]\n",
      " 98%|█████████▊| 761/780 [00:02<00:00, 313.74it/s][h264 @ 0x3585ebc0] error while decoding MB 74 67, bytestream -8\n",
      " 98%|█████████▊| 768/780 [00:02<00:00, 309.56it/s]\n",
      " 91%|█████████▏| 709/776 [00:02<00:00, 300.99it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 320.17it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 298.50it/s]\n",
      " 98%|█████████▊| 768/785 [00:02<00:00, 316.95it/s]\n",
      " 98%|█████████▊| 768/783 [00:02<00:00, 317.27it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 322.38it/s]\n",
      " 91%|█████████ | 709/777 [00:02<00:00, 302.27it/s]\n",
      " 98%|█████████▊| 768/784 [00:02<00:00, 312.62it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 302.45it/s]\n",
      " 91%|█████████▏| 709/775 [00:02<00:00, 304.88it/s]\n",
      " 93%|█████████▎| 709/763 [00:02<00:00, 303.70it/s]\n",
      " 92%|█████████▏| 709/769 [00:02<00:00, 299.42it/s]\n",
      " 93%|█████████▎| 709/764 [00:02<00:00, 300.11it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 297.56it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 320.40it/s]\n",
      " 93%|█████████▎| 709/765 [00:02<00:00, 308.50it/s]\n",
      " 94%|█████████▍| 709/756 [00:02<00:00, 303.46it/s]\n",
      " 93%|█████████▎| 709/761 [00:02<00:00, 303.99it/s]\n",
      " 98%|█████████▊| 768/782 [00:02<00:00, 318.40it/s]\n",
      " 97%|█████████▋| 473/489 [00:01<00:00, 270.38it/s]\n",
      " 92%|█████████▏| 709/770 [00:02<00:00, 302.90it/s]\n",
      " 98%|█████████▊| 768/787 [00:02<00:00, 322.51it/s]\n",
      " 98%|█████████▊| 768/786 [00:02<00:00, 322.83it/s]\n",
      " 65%|██████▍   | 508/786 [00:01<00:00, 311.91it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/transformers/trainer.py:2245\u001b[39m, in \u001b[36mTrainer.train\u001b[39m\u001b[34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[39m\n\u001b[32m   2243\u001b[39m         hf_hub_utils.enable_progress_bars()\n\u001b[32m   2244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2246\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2247\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/transformers/trainer.py:2514\u001b[39m, in \u001b[36mTrainer._inner_training_loop\u001b[39m\u001b[34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[39m\n\u001b[32m   2512\u001b[39m update_step += \u001b[32m1\u001b[39m\n\u001b[32m   2513\u001b[39m num_batches = args.gradient_accumulation_steps \u001b[38;5;28;01mif\u001b[39;00m update_step != (total_updates - \u001b[32m1\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m remainder\n\u001b[32m-> \u001b[39m\u001b[32m2514\u001b[39m batch_samples, num_items_in_batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_batch_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2515\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, inputs \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch_samples):\n\u001b[32m   2516\u001b[39m     step += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/transformers/trainer.py:5243\u001b[39m, in \u001b[36mTrainer.get_batch_samples\u001b[39m\u001b[34m(self, epoch_iterator, num_batches, device)\u001b[39m\n\u001b[32m   5241\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_batches):\n\u001b[32m   5242\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m5243\u001b[39m         batch_samples.append(\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m   5244\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   5245\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/accelerate/data_loader.py:577\u001b[39m, in \u001b[36mDataLoaderShard.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    575\u001b[39m     current_batch = send_to_device(current_batch, \u001b[38;5;28mself\u001b[39m.device, non_blocking=\u001b[38;5;28mself\u001b[39m._non_blocking)\n\u001b[32m    576\u001b[39m \u001b[38;5;28mself\u001b[39m._update_state_dict()\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m next_batch = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataloader_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch_index >= \u001b[38;5;28mself\u001b[39m.skip_batches:\n\u001b[32m    579\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m current_batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/torch/utils/data/dataloader.py:733\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    730\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    731\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    732\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m733\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    734\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    735\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    736\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    737\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    739\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/torch/utils/data/dataloader.py:789\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    788\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m789\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    790\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    791\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniconda3/envs/i_work/lib/python3.13/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     50\u001b[39m         data = \u001b[38;5;28mself\u001b[39m.dataset.__getitems__(possibly_batched_index)\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m         data = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     54\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.dataset[possibly_batched_index]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 65\u001b[39m, in \u001b[36mVideoDataset.__getitem__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     63\u001b[39m video_idx = index // \u001b[38;5;28mself\u001b[39m.frames_per_video\n\u001b[32m     64\u001b[39m frame_idx = index % \u001b[38;5;28mself\u001b[39m.frames_per_video\n\u001b[32m---> \u001b[39m\u001b[32m65\u001b[39m frames, label, _ = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvideo_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     66\u001b[39m frame = frames[frame_idx]\n\u001b[32m     67\u001b[39m \u001b[38;5;66;03m# frame = (frame - self.set_mean) / self.set_std\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36mVideoDataset.__load\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    119\u001b[39m last_valid_frame = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(frames) < \u001b[38;5;28mself\u001b[39m.frames_per_video:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     ret, frame = \u001b[43mcap\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ret:\n\u001b[32m    124\u001b[39m         \u001b[38;5;66;03m# Reached end of video early - pad with last valid frame\u001b[39;00m\n\u001b[32m    125\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m last_valid_frame \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"./HAR-med-finetuned\")\n",
    "processor.save_pretrained(\"./HAR-med-finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_video_level(model, dataset, device=\"cuda\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        sample = dataset[idx]\n",
    "        frames = sample[\"pixel_values\"].to(device)\n",
    "        label = sample[\"label\"]\n",
    "        with torch.no_grad():\n",
    "            logits = model(pixel_values=frames).logits\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            majority_pred = torch.mode(preds).values.item()\n",
    "        all_preds.append(majority_pred)\n",
    "        all_labels.append(label)\n",
    "    return (\n",
    "        accuracy_score(all_labels, all_preds),\n",
    "        *precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")[:3],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on video-based validation set\n",
    "accuracy, precision, recall, f1 = evaluate_video_level(model, val_set_video)\n",
    "print(\n",
    "    f\"Validation (Video-Level): Accuracy: {accuracy}, Precision: {precision}, Recall: {recall}, F1: {f1}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "i_work",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
